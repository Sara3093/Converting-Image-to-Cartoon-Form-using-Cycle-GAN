{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlIhpZWa7sgg",
        "outputId": "844098bf-aed4-461e-dbbe-ffd95859ef6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-FUMCBoxzHjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeae07dc-721f-4ecd-8155-710997c04d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "import numpy as np\n",
        "from numpy import savez_compressed\n",
        "import os\n",
        "from os import listdir\n",
        "import cv2\n",
        "from numpy import asarray, vstack, savez_compressed\n",
        "from numpy.random import randint\n",
        "from glob import glob\n",
        "from random import random\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import tensorflow.image as tfi\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import ReLU, Input,Conv2D,Dropout,LeakyReLU, Activation, Concatenate, Conv2DTranspose\n",
        "from keras.models import load_model,Model ,Sequential\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJh8x69e7x60",
        "outputId": "cc45344d-c464-400c-c201-75c296d3c46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Resizing all the images to 64*64 pixels and storing in compressed Numpy array.\n",
        "def load_images(path, size=(64, 64), max_images=None):\n",
        "    data_list = []\n",
        "    for filename in listdir(path):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):  # Filter for specific image file extensions\n",
        "            pixels = load_img(path + filename, target_size=size)\n",
        "            pixels = img_to_array(pixels)\n",
        "            data_list.append(pixels)\n",
        "            if max_images and len(data_list) >= max_images:\n",
        "                break\n",
        "    return np.asarray(data_list)\n",
        "\n",
        "celeb_path = '/content/drive/MyDrive/img_align_celeba1'\n",
        "cartoon_path = '/content/drive/MyDrive/cartoonset10k'\n",
        "\n",
        "dataA = load_images(celeb_path, max_images=1000)\n",
        "print('loaded dataA', dataA.shape)\n",
        "\n",
        "dataB = load_images(cartoon_path, max_images=1000)\n",
        "print('loaded dataB', dataB.shape)\n",
        "filename = 'celebrity2cartoon.npz'\n",
        "np.savez_compressed(filename, dataA=dataA, dataB=dataB)\n",
        "\n",
        "print('Saved dataset:', filename)"
      ],
      "metadata": {
        "id": "Bd8HL3aA8Twn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import load\n",
        "data = load('celebrity2cartoon.npz')\n",
        "daraA, dataB = data['dataA'], data['dataB']\n",
        "print('Loaded data:', dataA.shape, dataB.shape)\n",
        "n_samples = 4\n",
        "# plot original image\n",
        "for i in range (n_samples):\n",
        "    plt.subplot(2 , n_samples,1+i )\n",
        "    plt.axis('off')\n",
        "    plt.imshow(dataA[i].astype('uint8'))\n",
        "# plot target image\n",
        "for i in range (n_samples):\n",
        "    plt.subplot(2 , n_samples,1+n_samples+i )\n",
        "    plt.axis('off')\n",
        "    plt.imshow(dataB[i].astype('uint8'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "os2Fh_jw8X5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the discriminator model\n",
        "def define_discriminator(image_shape):\n",
        "    #weight initialization\n",
        "    init = RandomNormal(stddev = 0.02)\n",
        "    #source image input\n",
        "    input_image = Input(shape = image_shape)\n",
        "    #c64\n",
        "    x = Conv2D(64,(4,4), strides = 2 , padding = 'same', kernel_initializer = init)(input_image)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "    #c128\n",
        "    x = Conv2D(128,(4,4), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
        "    x = InstanceNormalization(axis = -1)(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "    #c256\n",
        "    x = Conv2D(256,(4,4), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
        "    x = InstanceNormalization(axis = -1)(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "       #c512\n",
        "    x = Conv2D(512,(4,4), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
        "    x = InstanceNormalization(axis = -1)(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "\n",
        "    x = Conv2D(512,(4,4) , padding = 'same', kernel_initializer = init)(x)\n",
        "    x = InstanceNormalization(axis = -1)(x)\n",
        "    x = LeakyReLU(alpha = 0.2)(x)\n",
        "\n",
        "    out_put = Conv2D(1, (4, 4), padding='same', kernel_initializer=init, use_bias=False)(x)\n",
        "\n",
        "    model = Model(input_image, out_put)\n",
        "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
        "\n",
        "    return model\n",
        "\n",
        "image_shape = (64, 64, 3)\n",
        "discriminator = define_discriminator(image_shape)\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "ugXnXdP6-4uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_block(filters, layer):\n",
        "    # weight initialization\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "\n",
        "    #print(layer.shape)  # print the shape of the previous layer\n",
        "\n",
        "    x = Conv2D(filters, (3,3), padding='same', kernel_initializer=init)(layer)\n",
        "    x = InstanceNormalization(axis=-1)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, (3,3), padding='same', kernel_initializer=init)(x)\n",
        "    x = InstanceNormalization(axis=-1)(x)\n",
        "\n",
        "    # skip connection\n",
        "    x = Concatenate()([x, layer])\n",
        "    return x"
      ],
      "metadata": {
        "id": "AWJnDv2a_II8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample(filters, layer, size=3, strides=2, activation=None, index=None, norm=True):\n",
        "    x = Conv2D(filters, kernel_size=size, strides=strides, padding ='same', kernel_initializer='he_normal', use_bias=False)(layer)\n",
        "    x = InstanceNormalization(axis=-1)(x)\n",
        "    x = LeakyReLU()(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "CXnkcm45_MFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the generator model\n",
        "def define_generator(image_shape, n_resnet=9):\n",
        "    #weight initialization\n",
        "    init = RandomNormal(stddev = 0.02)\n",
        "    #source image input\n",
        "    input_image = Input(shape = image_shape)\n",
        "    #c64\n",
        "    x = Conv2D(64,(7,7) , padding = 'same', kernel_initializer = init)(input_image)\n",
        "    x = InstanceNormalization(axis = -1)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    #c128\n",
        "    x = Conv2D(128,(3,3), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
        "    x = InstanceNormalization(axis = -1)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    #c256\n",
        "    x = Conv2D(256,(3,3), strides = 2 , padding = 'same', kernel_initializer = init)(x)\n",
        "    x = InstanceNormalization(axis = -1)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    for i in range(n_resnet):\n",
        "      x = resnet_block(256 , x)\n",
        "\n",
        "    # Add Conv2DTranspose layers to upscale the image to the desired shape\n",
        "    x = Conv2DTranspose(128, (3, 3), strides=2, padding='same', kernel_initializer=init)(x)\n",
        "    x = InstanceNormalization(axis=-1)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2DTranspose(64, (3, 3), strides=2, padding='same', kernel_initializer=init)(x)\n",
        "    x = InstanceNormalization(axis=-1)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(3, (7, 7), padding='same', kernel_initializer=init)(x)\n",
        "    x = InstanceNormalization(axis=-1)(x)\n",
        "    out_image = Activation('tanh')(x)\n",
        "\n",
        "    model = Model(input_image, out_image)\n",
        "    return model\n",
        "image_shape = (64, 64, 3)\n",
        "generator = define_generator(image_shape)\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "B_1-Uk0j_OqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda, Reshape\n",
        "\n",
        "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
        "    g_model_1.trainable = True\n",
        "    d_model.trainable = False\n",
        "    g_model_2.trainable = False\n",
        "\n",
        "    # Input for generated images\n",
        "    input_gen = Input(shape=image_shape)\n",
        "\n",
        "    # Resize generated images to the shape expected by the discriminator\n",
        "    resized_gen = Lambda(lambda x: tf.image.resize(x, (64, 64), method=tf.image.ResizeMethod.BILINEAR))(input_gen)\n",
        "\n",
        "    # Forward pass through the generator and discriminator\n",
        "    gen_1_out = g_model_1(resized_gen)\n",
        "    output_d = d_model(gen_1_out)\n",
        "\n",
        "    # Input for identity mapping\n",
        "    input_id = Input(shape=image_shape)\n",
        "\n",
        "    # Forward pass for identity map\n",
        "    input_id = Input(shape=image_shape)\n",
        "\n",
        "    # Forward pass for identity mapping\n",
        "    output_id = g_model_1(input_id)\n",
        "\n",
        "    # Forward and backward cycle loss\n",
        "    output_f = g_model_2(gen_1_out)\n",
        "    gen_2_out = g_model_2(input_id)\n",
        "    output_b = g_model_1(gen_2_out)\n",
        "\n",
        "    # Define the composite model\n",
        "    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
        "\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "B85FzpK7_iRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_real_samples(filename):\n",
        "    data = load(filename)\n",
        "    X1,X2 = data['dataA'],data['dataB']\n",
        "    X1 = (X1-127.5)/127.5 #for source image\n",
        "    X2 = (X2-127.5)/127.5 # for corresponding target images\n",
        "    return [X1,X2]"
      ],
      "metadata": {
        "id": "pCDPPloQ_r1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "    # choose random instances\n",
        "    ix = randint(0,dataset.shape[0], n_samples)\n",
        "    # retrieve selected images\n",
        "    X = dataset[ix]\n",
        "    # generate 'real' class labels (1)\n",
        "    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "_KmLZGTn_uM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##select a batch of random samples,return images and target\n",
        "def generate_fake_samples(g_model, dataset, patch_shape):\n",
        "    # Generate a batch of random noise as input for the generator\n",
        "    X = g_model.predict(dataset)\n",
        "\n",
        "    # Create 'fake' class labels (0)\n",
        "    y = np.zeros((len(X), patch_shape,patch_shape, 1))\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "p5JMzKc-_xsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the generator model to file\n",
        "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
        "    filename1 = 'g_model_AtoB_%06d.h5' %(step +1)\n",
        "    g_model_AtoB.save(filename1)\n",
        "    filename2 = 'g_model_BtoA_%06d.h5' %(step +1)\n",
        "    g_model_BtoA.save(filename2)\n",
        "    print('>saved:%s and %s' %(filename1,filename2))\n"
      ],
      "metadata": {
        "id": "Gul1zkNr_0RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#update image pool for fake image\n",
        "import random  # Import the random module\n",
        "\n",
        "def update_image_pool(pool, images, max_size=50):\n",
        "    selected = list()\n",
        "    for image in images:\n",
        "        if len(pool) < max_size:\n",
        "            # Stock the pool\n",
        "            pool.append(image)\n",
        "            selected.append(image)\n",
        "        elif random.random() < 0.5:  # Use random.random() instead of random() here\n",
        "            # Use image, but don't add it to the pool\n",
        "            selected.append(image)\n",
        "        else:\n",
        "            # Replace an existing image and use the replaced image\n",
        "            ix = np.random.randint(0, len(pool))\n",
        "            selected.append(pool[ix])\n",
        "            pool[ix] = image\n",
        "    return np.asarray(selected)  # This line should be outside the for loop"
      ],
      "metadata": {
        "id": "aQQaokuF_1Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image , title = None):\n",
        "    plt.imshow(image)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "BeFx1CFf_7f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_preds(g_AB, g_BA, n_images=1):\n",
        "    for i in range(n_images):\n",
        "        id = np.random.randint(len(dataA))\n",
        "        data = load('celebrity2cartoon.npz')\n",
        "        celeb, cartoon = dataA[id], dataB[id]\n",
        "        celeb_pred, cartoon_pred = g_BA.predict(tf.expand_dims(cartoon, axis=0))[0], g_AB.predict(tf.expand_dims(celeb, axis=0))[0]\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "\n",
        "        plt.subplot(1, 4, 1)\n",
        "        show_image(celeb.astype('uint8'), title='Original celeb')\n",
        "\n",
        "        plt.subplot(1, 4, 2)\n",
        "        show_image(cartoon_pred, title='Generated celeb')\n",
        "\n",
        "        plt.subplot(1, 4, 3)\n",
        "        show_image(cartoon.astype('uint8'), title='Original cartoon')\n",
        "\n",
        "        plt.subplot(1, 4, 4)\n",
        "        show_image(celeb_pred, title='Generated cartoon')\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "RBpDaPo4_9mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train cyclegan model\n",
        "def train(dataset,d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA,epochs=10, chunk=5):\n",
        "    #define peroperties of the training run\n",
        "    n_epochs, n_batch = epochs, 1\n",
        "    #determine the output square shape of discriminator\n",
        "    n_patch = d_model_A.output_shape[1]\n",
        "    #unpack dataset\n",
        "    trainA, trainB = dataset[0], dataset[1]\n",
        "    #prepare image pool for fakes\n",
        "    poolA, poolB = list(), list()\n",
        "    #calcute the number of batches per training epoch\n",
        "    batch_per_epoch = int(len(trainA)/n_batch)\n",
        "    #calcute the number of training iteration\n",
        "    n_steps = batch_per_epoch\n",
        "    #manually enumerate epochs\n",
        "    for j in tqdm(range(epochs), desc='Epochs'):\n",
        "        for i in tqdm(range(n_steps), desc='Batchs'):\n",
        "            #select a batch of real sample\n",
        "            X_realA, y_realA = generate_real_samples(trainA,n_batch, n_patch)\n",
        "            X_realB, y_realB = generate_real_samples(trainB,n_batch, n_patch)\n",
        "            #genarate a batch of fake sample\n",
        "            X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
        "            X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
        "            #update fakes from pool\n",
        "            X_fakeA = update_image_pool(poolA, X_fakeA)\n",
        "            X_fakeB = update_image_pool(poolB, X_fakeB)\n",
        "\n",
        "            #update generator B->A via adversarial and cycle loss\n",
        "            gen_loss2, _, _, _,_ = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
        "\n",
        "\n",
        "            # update discriminator for A->[real/fake]\n",
        "            dA_loss_1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
        "            dA_loss_2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
        "\n",
        "            #update generator A->B via adversarial and cycle loss\n",
        "            gen_loss1, _, _, _,_ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
        "\n",
        "            # update discriminator for B->[real/fake]\n",
        "            dB_loss_1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
        "            dB_loss_2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
        "            #summerize performance\n",
        "            print('>%d, dA[%.3f ,%.3f ] dB[%.3f ,%.3f] g[%.3f ,%.3f]' %(i+1,dA_loss_1,dA_loss_2, dB_loss_1,dB_loss_2,gen_loss1,gen_loss2))\n",
        "\n",
        "        if(j%chunk)==0:\n",
        "            show_preds(g_model_AtoB,g_model_BtoA, n_images=1)\n",
        "                #save the models\n",
        "            g_model_AtoB.save('Generator_Celebrity_to_Cartoon.h5')\n",
        "            g_model_BtoA.save('Generator_Cartoon_to_Celebrity.h5')"
      ],
      "metadata": {
        "id": "wLp-F4StACrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load image data\n",
        "dataset = load_real_samples ('celebrity2cartoon.npz')\n",
        "\n",
        "print ('Loaded',dataset[0].shape,dataset[1].shape)\n",
        "#define input shape based on the loaded dataset\n",
        "image_shape = dataset[0].shape[1:]\n",
        "#generator:A->B\n",
        "g_model_AtoB = define_generator(image_shape)\n",
        "#generator:B->A\n",
        "g_model_BtoA = define_generator(image_shape)\n",
        "#discriminator A-[real/fake]\n",
        "d_model_A = define_discriminator(image_shape)\n",
        "#discriminator B-[real/fake]\n",
        "d_model_B = define_discriminator(image_shape)\n",
        "#composite : A->B ->[real/fake ,A ]\n",
        "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B,g_model_BtoA,image_shape)\n",
        "#composite : B->A ->[real/fake ,B ]\n",
        "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A,g_model_AtoB,image_shape)\n",
        "train(dataset,d_model_A,d_model_B, g_model_AtoB,g_model_BtoA,c_model_AtoB, c_model_BtoA , epochs=10, chunk=5)"
      ],
      "metadata": {
        "id": "kXMk4oRAAwsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CelebtoCartoon_gen = load_model('/kaggle/working/Generator_Celebrity_to_Cartoon.h5')\n",
        "CartoontoCeleb_gen = load_model('/kaggle/working/Generator_Cartoon_to_Celebrity.h5')"
      ],
      "metadata": {
        "id": "ydZ6Tvt0AzYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_preds(CelebtoCartoon_gen,CartoontoCeleb_gen ,n_images=5)"
      ],
      "metadata": {
        "id": "zOvR62vtA3hN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}